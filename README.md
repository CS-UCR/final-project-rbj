# Team: RBJ

### Members 
- Jonathan Kim 
- Brendan Cheng 
- Rithvik Vukka

Our team is excited to go more in depth on the ethical aspect of data science. We are
especially interested in analyzing **differential privacy**.

### Link/Citation of related Research Papers
Project
1. [Differential Privacy and Machine Learning: a Survey and Review](https://arxiv.org/abs/1412.7584) - [Literature Review](https://github.com/CS-UCR/final-project-rbj/blob/main/summaries/Differential%20Privacy%20and%20Machine%20Learning%20A%20Survey%20and%20Review.md)
2. [A Novel Differential Privacy Approach that Enhances Classification Accuracy](https://dl.acm.org/doi/10.1145/2948992.2949027) - [Literature Review](https://github.com/CS-UCR/final-project-rbj/blob/main/summaries/A%20Novel%20Differential%20Privacy%20Approach%20that%20Enhances%20Classification%20Accuracy.md)
3. [Effects of Noise on Machine Learning Algorithms Using Local Differential Privacy Techniques](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9422609) - [Literature Review](https://github.com/CS-UCR/final-project-rbj/blob/main/summaries/Effects%20of%20Noise%20on%20Machine%20Learning%20Algorithms%20Using%20Local%20Differential%20Privacy%20Techniques.md)
4. [Differential Privacy Made Easy](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10007322) - [Literature Review](https://github.com/CS-UCR/final-project-rbj/blob/main/summaries/Differential%20Privacy%20Made%20Easy.md)
5. [Signal Processing and Machine Learning with Differential Privacy](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6582713) - [Literature Review](https://github.com/CS-UCR/final-project-rbj/blob/main/summaries/Signal%20Processing%20and%20Machine%20Learning%20with%20Differential%20Privacy.md)

### Description
Our project will involve researching differential privacy and its implementation into various techniques of data analysis. The concept of differential privacy is fairly recent, and can be implemented using a variety of mechanisms depending on the desired effects on data analysis. We seek to learn some of these mechanisms, as well as their benefits, their potential downsides, and the data analysis techniques that would benefit most from their implementation. We would also like to learn about how the additional noise generated by differential privacy might compound pre-existing noise in data, and how the downsides of such noise might be mitigated. We will also attempt to implement an algorithm for differential privacy to better understand the real-world implications of differential privacy, and how they might differ from the theoretical aspects discussed in academic papers.


### Dataset 
- We have used the iris dataset for our project. The dataset contains 150 samples of 3 different species of iris flowers. The dataset contains 4 features of each sample. 
- The features are sepal length, sepal width, petal length, and petal width. The target variable is the species of the flower. 
- The dataset is available on the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/iris). We choose this dataset because it is a small dataset and easy to visualize before and after adding noise to the data.

### Implementation
- We have implemented a simple machine learning algorithm to predict the species of the flower based on the features. 
- We have used the K-Nearest Neighbors, Logistic Regression, Random Forest Classifier algorithms to predict the species of the flower. This algorithm is inspired by the [Effects of Noise on Machine Learning Algorithms Using Local Differential Privacy Techniques](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9422609) paper.
- We have used the [scikit-learn](https://scikit-learn.org/stable/) library to implement the algorithm. We have used the [plotly](https://plotly.com/python/) library to visualize the data.
- We have trained the model before and after adding noise with these models and have found some results
    - The accuracy of the model is not affected by the noise added to the data.
    - When trained and tested on different models i.e., (trained on noise data and tested on non-noise data or vice versa) the accuracy of the model is not affected, but lower accuracy is found compared to training and testing on same dataset.
    - Random Forest Classifier is found to be the best model for this dataset and it is not affected by the noise added to the data.
    - Pearson correlation coefficient is not affected by the noise added to the data. Before and after adding noise the same features are found to be highly correlated with the target variable.

### Running the notebook on Jupyter or Google Colab

To run this notebook on Jupyter or Google Colab, please follow these steps:

1. Clone the repository or download the notebook file.
2. Upload the notebook to your Jupyter or Google Colab workspace.
3. Install any required packages by running the following command in a code cell:

```ipython
!pip install pandas numpy sklearn plotly
```

4. Run the code cells in the notebook to reproduce the results.


### Slides
Slides used for the presentation can be found [here](https://docs.google.com/presentation/d/e/2PACX-1vTPQGlRAhgOtQvznw7oWjcxE_dYr9pThI7dvekNsARCBShW2id5omxDBPrh8o7MP90w_s9XXHlaMb1B/pub?start=true&loop=true&delayms=3000).


### Changes after Presentation
- We have been asked why we took only the noise factor into account when calculating the accuracy of the model. We have added a script that calculates the accuracy of the model with various noise factor. The results of an instance are shown below.

```json
{0.1: 0.96,
 0.2: 0.9466666666666667,
 0.3: 0.94,
 0.4: 0.94,
 0.5: 0.9666666666666667,
 0.6: 0.6066666666666667,
 0.7: 0.9533333333333334,
 0.8: 0.7466666666666667,
 0.9: 0.62}
```

on multiple runs of the algorithm we have found that the noise factor `0.4` is getting highest accuracy compared to other values. The above results are the best score of [1000 runs](https://github.com/CS-UCR/final-project-rbj/blob/97376dd3ead49435b07e8ba294b3d8c5a11d678e/src/file.py#L79C26-L88) of the algorithm.

### Conclusion
- We have learned about the concept of differential privacy and its implementation into various techniques of data analysis. We have also learned about the benefits, the potential downsides, and the data analysis techniques that would benefit most from their implementation. We have also learned about how the additional noise generated by differential privacy might compound pre-existing noise in data, and how the downsides of such noise might be mitigated. **From out implemented algorithm, We found that noise added to the data is not a big factor in the accuracy of the model. We also found that the accuracy of the model is not affected by the noise factor.** We have also learned about the real-world implications of differential privacy, and how they might differ from the theoretical aspects discussed in academic papers.