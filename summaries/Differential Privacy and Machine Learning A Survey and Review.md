# Differential Privacy and Machine Learning: a Survey and Review
Paper Link:\
https://arxiv.org/pdf/1412.7584.pdf

## Introduction
The underlying purpose of machine learning is to use existing data to determine existing trends that may be useful for later analysis of similar data, whether that analysis includes classifications, predictions, or clusters of similar data. Machine learning algorithms use various models and attempt to determine the most accurate model for future use. The models naturally contain information about the data which they are trained on, which conflicts with recent initiatives to preserve the privacy of individuals' data. Previous understandings of privacy believed anonymization to be sufficient in protecting individuals' privacy, but various instances have proven such assumptions false. Anonymization often falls apart if an attacker has previous information about a particular individual, and, thus, identifying that individual within other datasets becomes quite easy. Other approaches to privacy that provide stronger guarantees than anonymization have also been developed, but the attributes of these approaches still allow attackers to make certain inferences about their target dataset. When combined with previous knowledge of particular individuals, these inferences can be used to de-anonymize individuals, and, as a result, privacy breaches are quite possible. Such inference techniques also work on aggregate statistics. Learning from the weaknesses of these approaches to privacy, differential privacy provides a novel approach to privacy which directly addresses differences between different datasets and limits the inferences which can be made based on those differences. As such, differential privacy seeks to provide higher standards of privacy for individuals and their data.