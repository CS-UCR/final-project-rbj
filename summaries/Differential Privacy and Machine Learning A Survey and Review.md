# Differential Privacy and Machine Learning: a Survey and Review
Paper Link:\
https://arxiv.org/pdf/1412.7584.pdf

## Introduction
The underlying purpose of machine learning is to use existing data to determine existing trends that may be useful for later analysis of similar data, whether that analysis includes classifications, predictions, or clusters of similar data. Machine learning algorithms use various models and attempt to determine the most accurate model for future use. The models naturally contain information about the data which they are trained on, which conflicts with recent initiatives to preserve the privacy of individuals' data. Previous understandings of privacy believed anonymization to be sufficient in protecting individuals' privacy, but various instances have proven such assumptions false. Anonymization often falls apart if an attacker has previous information about a particular individual, and, thus, identifying that individual within other datasets becomes quite easy. Other approaches to privacy that provide stronger guarantees than anonymization have also been developed, but the attributes of these approaches still allow attackers to make certain inferences about their target dataset. When combined with previous knowledge of particular individuals, these inferences can be used to de-anonymize individuals, and, as a result, privacy breaches are quite possible. Such inference techniques also work on aggregate statistics. Learning from the weaknesses of these approaches to privacy, differential privacy provides a novel approach to privacy which directly addresses differences between different datasets and limits the inferences which can be made based on those differences. As such, differential privacy seeks to provide higher standards of privacy for individuals and their data.

## Differential Privacy
### Definition
The following definition formalizes the concept of $(\epsilon, \delta)$-privacy.
$$P(\tilde{f}(D) \in S) \leq e^{\epsilon}P(\tilde{f}(D') \in S) + \delta$$
Under this definition, D and D' are two datasets with a distance of 1, where the distance between datasets is the amount of entries in which they differ. Such datasets are also referred to as neighboring datasets. $\tilde{f}$ simply refers to a random function which takes a dataset as an input and returns a random variable as an output. This output can be a discrete or continuous value, and does not necessarily have to be numeric. Lastly $\epsilon$ and $\delta$ are the 2 privacy parameters which serve as the basis of the strength of privacy guarantees for differential privacy. Using this definition of privacy, privacy can be understood to be enforced by $\tilde{f}$ if the probabilities of the outputs of 2 neighboring datasets fall within the bounds established by $\epsilon$ and $\delta$. The simplified case of $(\epsilon, 0)$-differential privacy is referred to as $\epsilon$-differential privacy, and simply has the additional expectation that there is no risk of data leakage. Under the weaker definition where $\delta$ is greater than 0, $\delta$ still must be sufficiently small, typically less than 1/n, to ensure privacy.
### Mechanisms
#### Laplace Mechanism
The Laplace mechansism is a popular method of noise generatio which satisfies $\epsilon$-differential privacy for numeric data in relation to the sensitivity of neighboring datasets. The sensitivity of neighboring datasets is defined as:
$$s(f, \|.\|) = \max_{d(D,\ D')}\|f(D) - f(D')\|,$$
where f is a query on the datasets adnd $\|.\|$ is a norm function, typically $L_{1}$ or $L_{2}$. The Laplace mechanism, then, is a random function which simply adds noise, $\eta$, to the output of a query, where $\eta$ is drawn from the Laplace distribution with density $p(\eta) \propto e^{-\epsilon\|\eta\|/s(f, \|.\|)}$. The Gausian mechanism is a variation which satisfies $(\epsilon, \delta)$-differential privacy by generating noise from a Gaussian distribution instead. The weaker privacy guarantees are exchanged for less extreme noise, and, as such, maintains higher utility of a dataset.
#### Exponential Mechansism
While the Laplace and Gaussian mechanisms generate noise for numeric data, numeric data is not the only data which exists. The exponential mechanism provides a more general privacy mechansism by employing a scoring function to determine the output of a given query. The mechanism functions by scoring each possible output and assigns probabilities in proportion to each outputs score and the sensitivity of the scoring function. Natually this scoring function favors accurate answers, but the introduction of probability introduces noise which is difficult to distinguish from real query answers.
#### Smooth Sensitivity Framework and Sample-and-Aggregate Framework
In some cases, generating large noise significantly reduces the utility of a dataset, so reduced noise may be desirable. Smooth sensitivity provides a framework where $(\epsilon, \delta)$-differential privacy can be maintained by producing noise in accordance to the database as well as the query being passed. This framework allows for reduced noise by avoiding worst-case sensitivity by using the concepts of local and smooth sensitivities. The previous definition of sensitivity is typically referred to as global sensitivity. Local senstitivity is defined as:
$$LS(f, \|.\|, D) = \max_{D':d(D, D') = 1}\|f(D) - f(D')\|$$
One might think that generating noise in accordance to local sensitivity would reduce the noise sufficiently, however such noise risks being significantly reduced when compared to the noise generated using global sensitivity. In such cases where noise becomes significantly reduced, privacy guarantees become too weak since the noise does not sufficiently randomize the result of a query. The Smooth Sensitvity framework addresses the oversight of using local sensitivity by using smooth sensitivity to scale Gaussian noise so that it is sufficient to guarantee privacy. The Sample-and-Aggregate framework avoids extreme noise by partitioning a dataset into $k$, small subsets, then estimating the desired query for each such subset. If the desired query can be accurately estimated using small subsets, the query results for the subsets will retain enough accuracy to be useful, though these estimates do not yet have any noise. After estimating the desired query, the subset results are the aggregated. After aggregating the subsets, the smooth sensitivity framework is then applied to introduce noise, which ensures differential privacy.
### Combination of Mechanisms
Sometimes different mechanisms may be used in sequence to ensure differential privacy across a series of queries. In such cases, differential privacy is maintained for the entire sequence of queries, as long as each query is performed using a differentially-private mechanism. The sequential theorem states that the $(\epsilon, \delta)$ privacy guarantees of a series of differentially private queries are equal to the sums of the respective $(\epsilon, \delta)$ guarantees for each query. Naturally, this allows $\epsilon$ to be split across the series of queries to ensure the total privacy guarantees are in accordance to a desired $\epsilon_{total}$, rather than an $\epsilon$ which is higher than desired, and thus has weaker privacy. The parallel theorem also addresses sequences of differential private mechanisms in accordance to the subsets of a dataset. If a differentially private mechanism is applied to each subset of a dataset, then any function using the respective outputs of $n$ subsets of a dataset will also yield differentially private outputs. Put simply, combining differentially private outputs yields differentially private outputs.

## Machine Learning
Machine learning is the concept of algorithmic learning that extracts information from a given dataset. A set of samples (or examples) is received as an input and the algorithm uses the provided distribution of data in order to draw holistic conclusions. A sample space (set of all samples) utilize the same set of variables which can be either categorical or numerical. Two types of learning that we then identify within machine learning is supervised learning and unsupervised learning. The first is a method in which we seek to predict labels for new examples while the latter is one where no labels are present and we want to identify structure in the dataset. 
There are various different kinds of machine learning models. A *regression* model predicts the numerical value $Y$ given a set of variables $X$. *Classification* models are similar, but the $Y$ variable is categorical while the $X$ is a set of variables. *Clustering* models will group unlabelled samples into various different groups based on the similarities amongst the samples. *Dimension reduction* models will find a projection from the original sample space to a low-dimensional space and preserves the useful pieces of data. Finally, *feature selection* will identify the most informative variables. 
With all these different options, a machine learning algorithm must select one particular model that suits the data best. This process is what we call *training*. 
### Performance Measurement
When comparing different mechanisms, it must be taken into consideration how difficult it truly is to have a universal standard to which we can compare models with. Arguably, there is a 'true model' available to which the comparison can be made, but there are different understandings of what that consists of so there are varying approaches in the comparison. Across other papers, the ways in which the data is analyzed differs such as what the true model is, the distance between two models, and how closeness is defined. These are several examples of inconsistencies across the analyses of different academic papers that lead to the conclusion that it is hard to compare and determine which mechanisms are "better". 
### General Ideas of Differentially Private Machine Learning Algorithms
With what was mentioned in the previous paragraph, there are different kinds of approaches across mechanisms that we want to note.
When first approaching a model, it can be learned in several different ways. A given algorithm may learn a model on untouched clean data and then use the Laplacian or exponential mechanism to create noise in the model. Another option would be to use the Laplacian or exponential mechanisms to apply noise to the output of each step within the process so there are multiple occasions in which noise is generated. Another method is called objective perturbation in which noise is added to the target function and the minimum/maximum of the function is the output model. One final example of an approach is one specifically designed for small sample sizes which split into smaller subsets and then combine the results of the subsets along with some noise. These are all general ideas that we may recognize when looking across machine learning algorithms
## Differentially Supervised Learning
Supervised machine learning is when the labels for training data are known and the goal is to predict accurate labels for a new example. In the following sections, we will address differentially private supervised machine learning algorithms. 
### Naive Bayes Model
The naive Bayes model is a classifier that predicts $Y$ based on the features in $X$. After considering the two assumptions that $X_j$ is conditionally indpendent given $Y$, and that for all numerical features in $X$ we see that $P(X|Y)$ is a normal distribution, the conditional probability looks like this:
$$P(Y|X_1,...,X_p) \alpha P(Y)\prod_{j=1}^{p}P(X_j|Y)$$
For an $\epsilon$-differentially private naive Bayes model, there is one more assumption that must be made. That is all values for features in the dataset are bounded by some known number. 
### Linear Regression
Linear regression is a model for predicting numerical values $Y$ where the value is modelled upon the linear combination $w^TX$ of features in $X$. $w$ contains the weights for each feature and is computed by minimizing square loss over the training set. 
### Linear SVM
Linear SVM is a classifier where the vector $w$ captures the model parameters. This model outputs a score $w^TX$ for features $X$ in a sample and $sign(w^TX)$ for $Y$. Parameter $w$ is computed by minimizing $C\Sigma_1max(0,1-y_i(w^Tx_i))+w^Tw/2$ while $C>0$ is the input. When sample space is bounded, the linear SVM meets the following two conditions: it computes $w$ by minimizing a convex and differentiable loss function $L(w)$ and a change in one sample leads to change in $L'(w)$. 
### Logistic Regression
Logistic regression is a model for binary classification. It predicts $P(Y=1|X)=1/(1+e^{-w^TX})$ given features in $X$. The parameters $w$ are trained by minimizing negative log-likelihood $\Sigma_i log(1+exp(-y_i w^Tx_i))$ for the training set. Regularized logistic regression has $w$ computed by minimizing $\Sigma_i log(1+exp(-y_i w^Tx_i)) + \lambda w^Tw$ over the training set {$(x_i,y_i)$} while $\lambda > 0$ sets strength of regularization. Assuming that the sample space is bounded, both models can be $\epsilon$-differentially private. 
### Kernel SVM
The Kernel SVM model uses the *kernel function* $K(,)$ that takes two samples for input and then produces a real number in the output. This model can be utilized as both a classification and regression. As a classifier, it takes features $X$ and predicts the label $Y=sign(\Sigma_i w_iK(X,x_i))$. For the regression, the prediction for $Y$ is $Y=\Sigma_i w_i K(X,x_i)$. The training samples for both the classifier and regression are $(x_i, y_i)$ where $w_i$ is the weight that is considered when computing. In order to have a private kernel SVM model with translation-invariant kernels, we approximate kernel functions in the original sample space with a linear kernel in another space in order to avoid publishing training data. If the kernel is not translation-invariant, then the previous method cannot be applied and a different approach must be taken. 
The Test Data-independent Learner (TTDP) mechanism publishes a model with $(\epsilon, \delta)$-differential privacy and trains a non-private kernel from private data and then approximates in a differentially private way. It is trained iteratively throughout a multiple-step process and then produces the a result that satisfies ${\epsilon, \delta)$-differential privacy.
### Decision Tree Learning
Decision tree classifiers will partition the sample space and assign labels to the partitions. The tree is is first constructed by placeing the entire sample space in the root partition. It then iteratively selects partitions and picks a variable and score function within. For categorical values, the value of that variable is placed accordingly into the appropriate partition. For numerical values, the value will be distributed according the particular threshold that has been set and dictates the placement. Partitioning will end when sample spaces are small enough or the number of samples in the partitions are too small. Afterwards, the tree is pruned by removing the unnecessary partitions from the tree and merges samples and sample spaces to the parent. There are several methods of approach to achieve a differentially private decision tree that are then explained in depth within the paper. 
### Online Convex Programming
Online Convex Programming (OCP) algorithms will address convex programming problems. They receive an sequence of functions as the input and then output a sequence of points from a convex set $C$. The definition for the target of this algorithm is shown with this formula:
$$R=\sum_{t=1}^T f_t(w_t)-min_{w \epsilon C}\sum_{t=1}^T f_t(w)$$

## Differentially Private Unsupervised Learning
Unsupervised learning is when no labels are associated with each training example. Without the labels, this type of learning can find structure in a dataset. By looking at specific characteristics, it can identify what group it is part of. With that being said, the goal is to then produce a differentially private unsupervised machine learning algorithm. 
### K-means clustering
This clustering model is first trained by taking $k$ randomly selected points which represent the groups that are being partitioned. Then the various different samples will be clustered to the nearest point and then the mean of the collection associated with that given point will be the value produced by the given group. To produce a $(\epsilon, \delta)$-differential private k-means clustering algorithm, it uses well-separated data and randomly splits the training set into subsets and runs the algorithm on the subsets to get an output. The smooth-sensitivity framework is then used to publish the output from the dense region in a differentially private manner. 
## Differentially Private Dimensionality Reduction
For high dimensional data, typically it is desired to produce a low-dimensional representation of it as well. This allows less degrees of freedom and will be less susceptible to overfitting in the model and lower sensitivity. There are several particular methods by which this can be attained. 
### Feature Selection
PrivateKD is a classification based on the assumption that all features are categorical and finite in its potential values. With the set of features $S$, a function $F(S)$ tells how many pairs of samples from different classes that features in $S$ can distinguish. The exponential mechanism is utilized in order to select features that allow for the greatest increase of $F(S')$. 
Another differentially private method proposed requires a "stable" target function where the function values do not change as a result of a change in the input sample or the output remains consistent despite changing to a random subset. 
### Principal Component Analysis
Principal Componenet Analysis (PCA) is popular for the purpose of dimension reduction. It takes $k$ orthogonal directions where data is projected to have the greatest variance. The original data is then represented by the projection on those $k$ directions, and this will reduce the dimensionality of the data. Iterative algorithms are used in order to produce differentially private mechanisms. With the use of eigenvectors, there are several different approaches that are further explained in this paper. 
## Statistical Estimators
Statistical estimators will calculate approximations of quantities of interest using the evidence from the dataset. Using information such as mean and variance, the estimators are able to draw out results from those statistics. However, when datasets are small and features are scarce, there is the potential for data leakage.
### Robust Statistics Estimator
This estimator is robust if for element $x$, we see that the limit exists where 
$$lim_{t \rightarrow 0}(T((1-t)P+t \delta_x)-T(P))/t$$
### Point Estimator
Point estimators uses a similar notation as the robust statistics estimator. This mechanism will take $D$ and split it into $k$ subsets. The differentially private mean of all $T(D_i)$ is used to approximate the value of function $T(D)$. The following conditions will determine accuracy of this estimator:
$${{T(D)-T(P)} \over {\sigma p / \sqrt{n}}} \rightarrow N(0,1)$$$$when$$$$ n \rightarrow +\infin$$
$$E[T(D)]-T(P)= O(1/n)$$
$$E[{({{|T(D)-T(P)|} \over {\sigma p/\sqrt{n}}})^3}] = O(1)$$
### M-estimator
The M-estimator depends on the function where the estimate comes from. It relies on function $m(,)$ where it takes a sample and paramater $\theta$ as input input in order to output a real number. The paramater $\theta$ is estimated by computing 
$$\hat{\theta}=argmin {1 \over n} \Sigma m(x_i, \theta)$$
The method divides the sample space into smaller cubes without using private data. It then adds noise using the Laplacian method and computes the density function by dividing the noise associated to the respective cube by the volume of the cube. 
