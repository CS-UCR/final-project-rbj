# Differential Privacy and Machine Learning: a Survey and Review
Paper Link:\
https://arxiv.org/pdf/1412.7584.pdf

## Introduction
The underlying purpose of machine learning is to use existing data to determine existing trends that may be useful for later analysis of similar data, whether that analysis includes classifications, predictions, or clusters of similar data. Machine learning algorithms use various models and attempt to determine the most accurate model for future use. The models naturally contain information about the data which they are trained on, which conflicts with recent initiatives to preserve the privacy of individuals' data. Previous understandings of privacy believed anonymization to be sufficient in protecting individuals' privacy, but various instances have proven such assumptions false. Anonymization often falls apart if an attacker has previous information about a particular individual, and, thus, identifying that individual within other datasets becomes quite easy. Other approaches to privacy that provide stronger guarantees than anonymization have also been developed, but the attributes of these approaches still allow attackers to make certain inferences about their target dataset. When combined with previous knowledge of particular individuals, these inferences can be used to de-anonymize individuals, and, as a result, privacy breaches are quite possible. Such inference techniques also work on aggregate statistics. Learning from the weaknesses of these approaches to privacy, differential privacy provides a novel approach to privacy which directly addresses differences between different datasets and limits the inferences which can be made based on those differences. As such, differential privacy seeks to provide higher standards of privacy for individuals and their data.

## Differential Privacy
### Definition
The following definition formalizes the concept of $(\epsilon, \delta)$-privacy.
$$P(\tilde{f}(D) \in S) \leq e^{\epsilon}P(\tilde{f}(D') \in S) + \delta$$
Under this definition, D and D' are two datasets with a distance of 1, where the distance between datasets is the amount of entries in which they differ. Such datasets are also referred to as neighboring datasets. $\tilde{f}$ simply refers to a random function which takes a dataset as an input and returns a random variable as an output. This output can be a discrete or continuous value, and does not necessarily have to be numeric. Lastly $\epsilon$ and $\delta$ are the 2 privacy parameters which serve as the basis of the strength of privacy guarantees for differential privacy. Using this definition of privacy, privacy can be understood to be enforced by $\tilde{f}$ if the probabilities of the outputs of 2 neighboring datasets fall within the bounds established by $\epsilon$ and $\delta$. The simplified case of $(\epsilon, 0)$-differential privacy is referred to as $\epsilon$-differential privacy, and simply has the additional expectation that there is no risk of data leakage. Under the weaker definition where $\delta$ is greater than 0, $\delta$ still must be sufficiently small, typically less than 1/n, to ensure privacy.
### Mechanisms
#### Laplace Mechanism
The Laplace mechansism is a popular method of noise generatio which satisfies $\epsilon$-differential privacy for numeric data in relation to the sensitivity of neighboring datasets. The sensitivity of neighboring datasets is defined as:
$$s(f, \|.\|) = \max_{d(D,\ D')}\|f(D) - f(D')\|,$$
where f is a query on the datasets adnd $\|.\|$ is a norm function, typically $L_{1}$ or $L_{2}$. The Laplace mechanism, then, is a random function which simply adds noise, $\eta$, to the output of a query, where $\eta$ is drawn from the Laplace distribution with density $p(\eta) \propto e^{-\epsilon\|\eta\|/s(f, \|.\|)}$. The Gausian mechanism is a variation which satisfies $(\epsilon, \delta)$-differential privacy by generating noise from a Gaussian distribution instead. The weaker privacy guarantees are exchanged for less extreme noise, and, as such, maintains higher utility of a dataset.
#### Exponential Mechansism
While the Laplace and Gaussian mechanisms generate noise for numeric data, numeric data is not the only data which exists. The exponential mechanism provides a more general privacy mechansism by employing a scoring function to determine the output of a given query. The mechanism functions by scoring each possible output and assigns probabilities in proportion to each outputs score and the sensitivity of the scoring function. Natually this scoring function favors accurate answers, but the introduction of probability introduces noise which is difficult to distinguish from real query answers.
#### Smooth Sensitivity Framework and Sample-and-Aggregate Framework
In some cases, generating large noise significantly reduces the utility of a dataset, so reduced noise may be desirable. Smooth sensitivity provides a framework where $(\epsilon, \delta)$-differential privacy can be maintained by producing noise in accordance to the database as well as the query being passed. This framework allows for reduced noise by avoiding worst-case sensitivity by using the concepts of local and smooth sensitivities. The previous definition of sensitivity is typically referred to as global sensitivity. Local senstitivity is defined as:
$$LS(f, \|.\|, D) = \max_{D':d(D, D') = 1}\|f(D) - f(D')\|$$
One might think that generating noise in accordance to local sensitivity would reduce the noise sufficiently, however such noise risks being significantly reduced when compared to the noise generated using global sensitivity. In such cases where noise becomes significantly reduced, privacy guarantees become too weak since the noise does not sufficiently randomize the result of a query. The Smooth Sensitvity framework addresses the oversight of using local sensitivity by using smooth sensitivity to scale Gaussian noise so that it is sufficient to guarantee privacy. The Sample-and-Aggregate framework avoids extreme noise by partitioning a dataset into $k$, small subsets, then estimating the desired query for each such subset. If the desired query can be accurately estimated using small subsets, the query results for the subsets will retain enough accuracy to be useful, though these estimates do not yet have any noise. After estimating the desired query, the subset results are the aggregated. After aggregating the subsets, the smooth sensitivity framework is then applied to introduce noise, which ensures differential privacy.
### Combination of Mechanisms
Sometimes different mechanisms may be used in sequence to ensure differential privacy across a series of queries. In such cases, differential privacy is maintained for the entire sequence of queries, as long as each query is performed using a differentially-private mechanism. The sequential theorem states that the $(\epsilon, \delta)$ privacy guarantees of a series of differentially private queries are equal to the sums of the respective $(\epsilon, \delta)$ guarantees for each query. Naturally, this allows $\epsilon$ to be split across the series of queries to ensure the total privacy guarantees are in accordance to a desired $\epsilon_{total}$, rather than an $\epsilon$ which is higher than desired, and thus has weaker privacy. The parallel theorem also addresses sequences of differential private mechanisms in accordance to the subsets of a dataset. If a differentially private mechanism is applied to each subset of a dataset, then any function using the respective outputs of $n$ subsets of a dataset will also yield differentially private outputs. Put simply, combining differentially private outputs yields differentially private outputs.

## Machine Learning
Machine learning is the concept of algorithmic learning that extracts information from a given dataset. A set of samples (or examples) is received as an input and the algorithm uses the provided distribution of data in order to draw holistic conclusions. A sample space (set of all samples) utilize the same set of variables which can be either categorical or numerical. Two types of learning that we then identify within machine learning is supervised learning and unsupervised learning. The first is a method in which we seek to predict labels for new examples while the latter is one where no labels are present and we want to identify structure in the dataset. 
There are various different kinds of machine learning models. A *regression* model predicts the numerical value $Y$ given a set of variables $X$. *Classification* models are similar, but the $Y$ variable is categorical while the $X$ is a set of variables. *Clustering* models will group unlabelled samples into various different groups based on the similarities amongst the samples. *Dimension reduction* models will find a projection from the original sample space to a low-dimensional space and preserves the useful pieces of data. Finally, *feature selection* will identify the most informative variables. 
With all these different options, a machine learning algorithm must select one particular model that suits the data best. This process is what we call *training*. 
### Performance Measurement
When comparing different mechanisms, it must be taken into consideration how difficult it truly is to have a universal standard to which we can compare models with. Arguably, there is a 'true model' available to which the comparison can be made, but there are different understandings of what that consists of so there are varying approaches in the comparison. Across other papers, the ways in which the data is analyzed differs such as what the true model is, the distance between two models, and how closeness is defined. These are several examples of inconsistencies across the analyses of different academic papers that lead to the conclusion that it is hard to compare and determine which mechanisms are "better". 
### General Ideas of Differentially Private Machine Learning Algorithms
With what was mentioned in the previous paragraph, there are different kinds of approaches across mechanisms that we want to note.
When first approaching a model, it can be learned in several different ways. A given algorithm may learn a model on untouched clean data and then use the Laplacian or exponential mechanism to create noise in the model. Another option would be to use the Laplacian or exponential mechanisms to apply noise to the output of each step within the process so there are multiple occasions in which noise is generated. Another method is called objective perturbation in which noise is added to the target function and the minimum/maximum of the function is the output model. One final example of an approach is one specifically designed for small sample sizes which split into smaller subsets and then combine the results of the subsets along with some noise. These are all general ideas that we may recognize when looking across machine learning algorithms
## Differentially Supervised Learning
Supervised machine learning is when the labels for training data are known and the goal is to predict accurate labels for a new example. In the following sections, we will address differentially private supervised machine learning algorithms. 
### Naive Bayes Model
The naive Bayes model is a classifier that predicts $Y$ based on the features in $X$. After considering the two assumptions that $X_j$ is conditionally indpendent given $Y$, and that for all numerical features in $X$ we see that $P(X|Y)$ is a normal distribution, the conditional probability looks like this:
$$P(Y|X_1,...,X_p) \alpha P(Y)\prod_{j=1}^{p}P(X_j|Y)$$
For an $\epsilon$-differentially private naive Bayes model, there is one more assumption that must be made. That is all values for features in the dataset are bounded by some known number. 
### Linear Regression
Linear regression is a model for predicting numerical values $Y$ where the value is modelled upon the linear combination $w^TX$ of features in $X$. $w$ contains the weights for each feature and is computed by minimizing square loss over the training set. 
### Linear SVM
Linear SVM is a classifier where the vector $w$ captures the model parameters. This model outputs a score $w^TX$ for features $X$ in a sample and $sign(w^TX)$ for $Y$. Parameter $w$ is computed by minimizing $C\Sigma_1max(0,1-y_i(w^Tx_i))+w^Tw/2$ while $C>0$ is the input. When sample space is bounded, the linear SVM meets the following two conditions: it computes $w$ by minimizing a convex and differentiable loss function $L(w)$ and a change in one sample leads to change in $L'(w)$. 
### Logistic Regression
Logistic regression is a model for binary classification. It predicts $P(Y=1|X)=1/(1+e^{-w^TX})$ given features in $X$. The parameters $w$ are trained by minimizing negative log-likelihood $\Sigma_i log(1+exp(-y_i w^Tx_i))$ for the training set. Regularized logistic regression has $w$ computed by minimizing $\Sigma_i log(1+exp(-y_i w^Tx_i)) + \lambda w^Tw$ over the training set {$(x_i,y_i)$} while $\lambda > 0$ sets strength of regularization. Assuming that the sample space is bounded, both models can be $\epsilon$-differentially private. 
